# 第四章

## Fisher线型判别分析(LDA)

>在二分类问题中

1. 求出投影前类均值<img src="https://latex.codecogs.com/gif.latex?\inline&space;m_{i}" title="m_{i}" />
1. 计算投影前类内离散度矩阵<img src="https://latex.codecogs.com/gif.latex?\inline&space;S_{\omega}&space;=&space;S_{1}&space;&plus;&space;S_{2}" title="S_{\omega} = S_{1} + S_{2}" />，其中(<img src="https://latex.codecogs.com/gif.latex?\inline&space;S_{i}&space;=&space;\sum(x_{j}&space;-&space;m_{i})(x_{j}&space;-&space;m_{i})^{T}" title="S_{i} = \sum(x_{j} - m_{i})(x_{j} - m_{i})^{T}" />)
1. 计算最优投影方向<img src="https://latex.codecogs.com/gif.latex?\inline&space;\omega^{*}&space;=&space;S_{\omega}^{-1}&space;*&space;(m1-&space;m2)" title="\omega^{*} = S_{\omega}^{-1} * (m1- m2)" />
1. 计算出分类阈值<img src="https://latex.codecogs.com/gif.latex?\inline&space;\omega_{0}&space;=&space;-\frac{1}{2}(m_{1}&space;&plus;&space;m_{2})S_{\omega}^{-1}(m_{1}&space;-&space;m_{2})&space;-&space;ln\frac{P(\omega&space;_{2})}{P(\omega&space;_{1})}" title="\omega_{0} = -\frac{1}{2}(m_{1} + m_{2})S_{\omega}^{-1}(m_{1} - m_{2}) - ln\frac{P(\omega _{2})}{P(\omega _{1})}" />，如果不考虑先验概率的不同，则可以采用阈值<img src="https://latex.codecogs.com/gif.latex?\inline&space;\omega_{0}&space;=&space;-\frac{1}{2}(\widetilde{m}_{1}&space;&plus;&space;\widetilde{m}_{2})" title="\omega_{0} = -\frac{1}{2}(\widetilde{m}_{1} + \widetilde{m}_{2})" />(其中<img src="https://latex.codecogs.com/gif.latex?\inline&space;\widetilde{m}_{i}&space;=&space;\omega^{T}m_{i}" title="\widetilde{m}_{i} = \omega^{T}m_{i}" />)

## 多类线性分类器

>转化为多个两类分类问题：

* C类转化为 C－1个两类问题:<img src="https://latex.codecogs.com/gif.latex?\inline&space;\omega_{i}" title="\omega_{i}" />与非<img src="https://latex.codecogs.com/gif.latex?\inline&space;\omega_{i}" title="\omega_{i}" />

One-vs-rest, one-over-all

* 每类转化为 C－1个两类问题（pairwise）

## LDA方法

*__优点:__*

1. 在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识；
1. LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。

*__缺点:__*

1. LDA不适合对非高斯分布样本进行降维，PCA也有这个问题；
1. LDA降维最多降到类别数C-1的维数，如果我们降维的维度大于C-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题；
1. LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好；
1. LDA可能过度拟合数据。

## 感知机

### 感知机算法

感知机(Perceptron)算法是一种很好的二分类在线算法，它要求是线性可分的模型，感知机对应于在输入的空间中将实例划分成正负样本，分离它们的是分离超平面，即判别的模型。
即可用一个决策边界`w*x+b`将正负样本进行区分。其中w为权重，b为偏置项。`(w*x1+b)>0`被分为正样本，否则为负样本。

### 感知机学习策略

假定要本线性可分，感知机的学习目标就是求的能将正负要本完全正确分开的分离超平面，即要寻找w,b，因此要确定一个学习策略，即定义损失函数并使其最小化。而感知机所采用的损失函数为所有误分点到超平面的距离。  
<img src="http://latex.codecogs.com/png.latex?L(w,b)=&space;-\sum_{x_{i}\in&space;M}y_{i}(w*x_{i}&plus;b)" title="L(w,b)= -\sum_{x_{i}\in M}y_{i}(w*x_{i}+b)" />