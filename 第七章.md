# 第七章

## 特征提取

>通过映射（或变换）的方法把原始特征变换为较少的新特征（二次特征）。

## 特征选择

>从原始特征中挑选出一些最具有代表性、最有利于分类的特征作为输入分类器的特征。

`关键：`选择合适的特征（特征集合）重要性度量（可分性测度）。

## 基于类内类间距离的可分性判据

>不同类别分布于特征空间中的不同区域，区域越分离，类别的可分性越好，因此可以使用类内类间距离来构造类别的可分性判据。
`ps:近邻法`

## 基于概率分布的可分性判据

分布密度的交叠程度可用分布密度函数<img src="https://latex.codecogs.com/gif.latex?\inline&space;p(x|\omega_{1})" title="p(x|\omega_{1})" />和<img src="https://latex.codecogs.com/gif.latex?\inline&space;p(x|\omega_{2})" title="p(x|\omega_{2})" />之间的距离来度量。
 任何函数<img src="https://latex.codecogs.com/gif.latex?\inline&space;J_{p}&space;=&space;\int&space;g[p(x|\omega_{1}),p(x|\omega_{2}),P_{1},P_{2}]" title="J_{p} = \int g[p(x|\omega_{1}),p(x|\omega_{2}),P_{1},P_{2}]" />只要满足一定条件就可以用来作为类别分离度的概率距离度量。
* 非负性，即<img src="https://latex.codecogs.com/gif.latex?\inline&space;J_{p}&space;\geq&space;0" title="J_{p} \geq 0" />。
* 当两类完全不交叠时，<img src="https://latex.codecogs.com/gif.latex?\inline&space;J_{p}" title="J_{p}" />取最大值。
* 当两类分布密度完全相同时，<img src="https://latex.codecogs.com/gif.latex?\inline&space;J_{p}" title="J_{p}" />应为0。

## 基于熵函数的可分性判据

`熵`在信息论里则叫信息量，即`熵`是对不确定性的度量。从控制论的角度来看，应叫不确定性。在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。  
在判断某些特征的类别可分性时，可以观察该特征对于类别判断的不确定程度，因此引入了熵的概念。
>具有最小不确定性（熵）的特征对于进行分类最为有利。

## 特征选择的最优搜索算法

从m个特征中挑选出d个特征，若要寻找到最优的特征组合，必须对所有的组合情况加以比较（穷举法）。唯一能取得最优结果的搜索方法是`分支定界`算法。

* 优点：
  1. 可以寻找到全局最优；
  1. 特定的挑选舍弃策略，可以减少计算量。

* 缺点：
  1. 当特征维数m非常大时，搜索最优解的时间复杂度还是非常的大；
  1. 可分性判据必须满足单调性。

## 次优搜索算法

最优搜索法虽然能够保证找到最优特征组合，但是在有些情况下计算量仍然太大难以实现。因此，必须考虑放弃最优解，通过较小计算量的方法寻找满足条件的次优解——次优搜索算法。

### 单独最优特征组合

使用可分性判据单独计算各个特征所对应的判据值，取最大的d个特征作为作为特征选择的结果。

* 只有特征的判据值满足一定的关系，才可以选出最优的特征组合。
* 即使各特征相互独立，也不一定能够得到最优解。

### 顺序前进法

最简单的自下而上的搜索方法。每次从待选特征中选择出一个特征，使其与已选的特征组合在一起所的的判据值最大，直到特征数满足要求为止。

* 考虑了所选特征与已选特征间的相关性，未考虑所选特征与剩余特征间的相关性关系。

### 顺序后退法

一种自上而下的方法，从全体特征开始，每次删除一个特征，所剔除的特征应使仍然保留的特征组合的判据值最大，直至剩余的特征数满足要求。

* 估计了每去掉一个特征所造成可分性的降低程度。
* 在高维空间计算判据值，计算量比顺序前进法要大。

## 基于优化的特征选择方法

特征选择问题是个组合优化问题，因此可以选择使用解决优化问题的方法来实现特征选择。

可用于特征选择优化求解方法：

* 模拟退火算法
* 遗传算法
* 禁忌搜索